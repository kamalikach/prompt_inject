{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417a0f70-7ac7-48a0-80a0-39763828dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from base64 import b64encode\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import fitz \n",
    "\n",
    "#sys.modules['pymupdf_fitz'] = pymupdf_fitz\n",
    "api_key = os.getenv(\"GCP_API_KEY\")\n",
    "model_name = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b503f7c5-26ff-4938-823b-d27d927d7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_by_estimated_tokens(text, max_tokens=1000):\n",
    "    estimated_words = int(max_tokens * 0.75)\n",
    "    return ' '.join(text.split()[:estimated_words])\n",
    "\n",
    "def build_reviewer_message(reviewer_prompt, file_content, cfg):\n",
    "    #if there is a token limit, then truncate the text of the file approximately\n",
    "    if 'max_tokens' in cfg:\n",
    "        file_content['text'] = truncate_by_estimated_tokens(file_content['text'], cfg['max_tokens'])\n",
    "        \n",
    "    prompt_text = reviewer_prompt['before'] + file_content['text'] + reviewer_prompt['after']        \n",
    "    return [{\"role\": \"user\", \"content\": prompt_text}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfcb5c5-d169-423a-a8e7-bdc100cee2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(file_path):\n",
    "    #given an open pdf file descriptor return text from it\n",
    "    doc = fitz.open(file_path)\n",
    "    all_text = [page.get_text() for page in doc if page.get_text().strip()]\n",
    "    doc.close()\n",
    "    return {'text': \"\\n\".join(all_text), 'image_paths': []}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd4b373-2086-43c2-8aeb-483b8b582703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pdf_file_name, model, reviewer_prompt, extract_content, expt_cfg={}):\n",
    "    #given an open pdf_file descriptor, extract content from the file\n",
    "    #then send it to the model with added reviewer prompt, and return text of the response\n",
    "    content = extract_content(pdf_file_name)\n",
    "    messages = build_reviewer_message(reviewer_prompt, content, expt_cfg)\n",
    "\n",
    "    try:\n",
    "        return completion(model=model, messages=messages, api_key=expt_cfg['api_key'])[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except (KeyError, IndexError, TypeError) as e:\n",
    "        return f\"[Error parsing response: {e}]\"\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4652308-dc3f-4502-8eba-7755ed9a2a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Write a review for this paper. Begin paper Under review as a conference paper at ICLR 2024 OUT-OF-DISTRIBUTION DETECTION WITH HYPERSPHERICAL ENERGY Anonymous authors Paper under double-blind review ABSTRACT The ability to detect if inputs are out-of-distribution (OOD) is essential to guarantee the reliability and safety of machine learning models that are deployed in an open environment. Recent studies have shown that an energy-based score is effective. However, unconstrained energy scores from a model trained with cross-entropy loss may not necessarily reflect the End of paper'}]\n"
     ]
    }
   ],
   "source": [
    "y = extract_text('./6sfRRcynDy_RandomCitation.pdf')\n",
    "\n",
    "reviewer_prompt = { 'before': 'Write a review for this paper. Begin paper ', \n",
    "                    'after': ' End of paper'}\n",
    "\n",
    "cfg = {'max_tokens': 100 }\n",
    "\n",
    "m = build_reviewer_message(reviewer_prompt, y, cfg)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a56a20-8a43-411a-a3e7-527ccfaa906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:45:32 - LiteLLM:ERROR\u001b[0m: vertex_llm_base.py:434 - Failed to load vertex credentials. Check to see if credentials containing partial/invalid information. Error: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "Traceback (most recent call last):\n",
      "  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 430, in get_access_token\n",
      "    _credentials, credential_project_id = self.load_auth(\n",
      "                                          ^^^^^^^^^^^^^^^\n",
      "  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 114, in load_auth\n",
      "    creds, creds_project_id = self._credentials_from_default_auth(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 160, in _credentials_from_default_auth\n",
      "    return google_auth.default(scopes=scopes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/google/auth/_default.py\", line 685, in default\n",
      "    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "google.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\nTraceback (most recent call last):\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2675, in completion\n    model_response = vertex_chat_completion.completion(  # type: ignore\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1811, in completion\n    _auth_header, vertex_project = self._ensure_access_token(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 266, in _ensure_access_token\n    return self.get_access_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 437, in get_access_token\n    raise e\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 430, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 114, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 160, in _credentials_from_default_auth\n    return google_auth.default(scopes=scopes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/google/auth/_default.py\", line 685, in default\n    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\ngoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/main.py:2675\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   2672\u001b[39m     litellm_params.get(\u001b[33m\"\u001b[39m\u001b[33mbase_model\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgemini\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m litellm_params[\u001b[33m\"\u001b[39m\u001b[33mbase_model\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2674\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2675\u001b[39m     model_response = \u001b[43mvertex_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgemini_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2695\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2696\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model:\n\u001b[32m   2697\u001b[39m     \u001b[38;5;66;03m# Vertex Model Garden - OpenAI compatible models\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py:1811\u001b[39m, in \u001b[36mVertexLLM.completion\u001b[39m\u001b[34m(self, model, messages, model_response, print_verbose, custom_llm_provider, encoding, logging_obj, optional_params, acompletion, timeout, vertex_project, vertex_location, vertex_credentials, gemini_api_key, litellm_params, logger_fn, extra_headers, client, api_base)\u001b[39m\n\u001b[32m   1807\u001b[39m should_use_v1beta1_features = \u001b[38;5;28mself\u001b[39m.is_using_v1beta1_features(\n\u001b[32m   1808\u001b[39m     optional_params=optional_params\n\u001b[32m   1809\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1811\u001b[39m _auth_header, vertex_project = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ensure_access_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1812\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1813\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertex_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1814\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1815\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1817\u001b[39m auth_header, url = \u001b[38;5;28mself\u001b[39m._get_token_and_url(\n\u001b[32m   1818\u001b[39m     model=model,\n\u001b[32m   1819\u001b[39m     gemini_api_key=gemini_api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1827\u001b[39m     should_use_v1beta1_features=should_use_v1beta1_features,\n\u001b[32m   1828\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:266\u001b[39m, in \u001b[36mVertexBase._ensure_access_token\u001b[39m\u001b[34m(self, credentials, project_id, custom_llm_provider)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_access_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:437\u001b[39m, in \u001b[36mVertexBase.get_access_token\u001b[39m\u001b[34m(self, credentials, project_id)\u001b[39m\n\u001b[32m    434\u001b[39m     verbose_logger.exception(\n\u001b[32m    435\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to load vertex credentials. Check to see if credentials containing partial/invalid information. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:430\u001b[39m, in \u001b[36mVertexBase.get_access_token\u001b[39m\u001b[34m(self, credentials, project_id)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     _credentials, credential_project_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject_id\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:114\u001b[39m, in \u001b[36mVertexBase.load_auth\u001b[39m\u001b[34m(self, credentials, project_id)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     creds, creds_project_id = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_credentials_from_default_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.googleapis.com/auth/cloud-platform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m project_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py:160\u001b[39m, in \u001b[36mVertexBase._credentials_from_default_auth\u001b[39m\u001b[34m(self, scopes)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle_auth\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgoogle_auth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/google/auth/_default.py:685\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x = \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./6sfRRcynDy_RandomCitation.pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreviewer_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtest\u001b[39m\u001b[34m(pdf_file_name, model, reviewer_prompt, extract_content, expt_cfg)\u001b[39m\n\u001b[32m      5\u001b[39m messages = build_reviewer_message(reviewer_prompt, content, expt_cfg)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpt_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapi_key\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Error parsing response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/utils.py:1309\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1306\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1307\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1308\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1309\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/utils.py:1184\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1182\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1183\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1187\u001b[39m     kwargs=kwargs,\n\u001b[32m   1188\u001b[39m     call_type=call_type,\n\u001b[32m   1189\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/main.py:3427\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3425\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3426\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3427\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3430\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2301\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2300\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prompt_inject/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2277\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2270\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m   2271\u001b[39m                 message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(exception_provider, error_str),\n\u001b[32m   2272\u001b[39m                 llm_provider=custom_llm_provider,\n\u001b[32m   2273\u001b[39m                 model=model,\n\u001b[32m   2274\u001b[39m                 request=original_exception.request,\n\u001b[32m   2275\u001b[39m             )\n\u001b[32m   2276\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2277\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m   2278\u001b[39m                 message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2279\u001b[39m                     \u001b[38;5;28mstr\u001b[39m(original_exception), traceback.format_exc()\n\u001b[32m   2280\u001b[39m                 ),\n\u001b[32m   2281\u001b[39m                 llm_provider=custom_llm_provider,\n\u001b[32m   2282\u001b[39m                 model=model,\n\u001b[32m   2283\u001b[39m                 request=httpx.Request(\n\u001b[32m   2284\u001b[39m                     method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2285\u001b[39m                 ),  \u001b[38;5;66;03m# stub the request\u001b[39;00m\n\u001b[32m   2286\u001b[39m             )\n\u001b[32m   2287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2288\u001b[39m     \u001b[38;5;66;03m# LOGGING\u001b[39;00m\n\u001b[32m   2289\u001b[39m     exception_logging(\n\u001b[32m   2290\u001b[39m         logger_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2291\u001b[39m         additional_args={\n\u001b[32m   (...)\u001b[39m\u001b[32m   2295\u001b[39m         exception=e,\n\u001b[32m   2296\u001b[39m     )\n",
      "\u001b[31mAPIConnectionError\u001b[39m: litellm.APIConnectionError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\nTraceback (most recent call last):\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2675, in completion\n    model_response = vertex_chat_completion.completion(  # type: ignore\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/gemini/vertex_and_google_ai_studio_gemini.py\", line 1811, in completion\n    _auth_header, vertex_project = self._ensure_access_token(\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 266, in _ensure_access_token\n    return self.get_access_token(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 437, in get_access_token\n    raise e\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 430, in get_access_token\n    _credentials, credential_project_id = self.load_auth(\n                                          ^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 114, in load_auth\n    creds, creds_project_id = self._credentials_from_default_auth(\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/litellm/llms/vertex_ai/vertex_llm_base.py\", line 160, in _credentials_from_default_auth\n    return google_auth.default(scopes=scopes)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/private/home/kamalika/prompt_inject/.venv/lib/python3.12/site-packages/google/auth/_default.py\", line 685, in default\n    raise exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\ngoogle.auth.exceptions.DefaultCredentialsError: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n"
     ]
    }
   ],
   "source": [
    "x = test('./6sfRRcynDy_RandomCitation.pdf', model_name, reviewer_prompt, extract_text, cfg)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00aea7-c7b3-43b6-9fba-aea776088f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python prompt_inject",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
